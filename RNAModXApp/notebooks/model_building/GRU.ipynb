{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_6B2KQKXP3C",
        "outputId": "fc99f19a-fa07-442f-9d81-77f071da1a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.0.1+cu118)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.7.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch) (16.0.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "import csv\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from numpy import array\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "from sklearn.metrics import accuracy_score ,  roc_curve, auc , classification_report\n"
      ],
      "metadata": {
        "id": "jPOhul3QXqB_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BINARY_DATA_PATH = \"../../../data/hAm_with_ROS.csv\"\n",
        "\n",
        "# If you running with dataset on drive . Use below code to mount on drive.\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "BINARY_DATA_PATH = \"/content/drive/My Drive/Colab Notebooks/Capstone Project/data/hAm_with_ROS.csv\"\n",
        "\n",
        "\n",
        "\n",
        "x_train_raw =  pd.read_csv(BINARY_DATA_PATH, header=None , skiprows=1 )\n",
        "# x_train_raw\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jaj5iwdtXsOw",
        "outputId": "c2f75478-cf8c-4397-86d3-1dc21e934c33"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of Input Data : {x_train_raw.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79vDu0ZhX2vp",
        "outputId": "d0bf184f-b703-4923-84da-e1abe7d83aab"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Input Data : (309214, 102)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "number_of_unique_kmers = set()\n",
        "def one_hot_encode_sequence(kmer_token):\n",
        "\n",
        "    # A 1 0 0 0\n",
        "    # C 0 1 0 0\n",
        "    # T/U 0 0 0 1\n",
        "    # G 0 0 1 0\n",
        "    # N 0 0 0 0\n",
        "\n",
        "    encoding_dict = {\n",
        "        'A': [1, 0, 0, 0],\n",
        "        'C': [0, 1, 0, 0],\n",
        "        'G': [0, 0, 1, 0],\n",
        "        'T': [0, 0, 0, 1],\n",
        "        'U': [0, 0, 0, 1],\n",
        "        'N': [0, 0, 0, 0],\n",
        "    }\n",
        "\n",
        "    encoded_sequence = []\n",
        "    number_of_unique_kmers.add(kmer_token)\n",
        "    for  base in kmer_token:\n",
        "        encoded_sequence.append(encoding_dict[base])\n",
        "    return np.array(encoded_sequence).flatten()\n",
        "\n",
        "def applyOneHotEncoding(tokenized_sequences):\n",
        "    encoded_sequences = []\n",
        "    for seq in tokenized_sequences:\n",
        "        encoded_sequences.append(one_hot_encode_sequence(seq))\n",
        "    return np.array(encoded_sequences).flatten()\n",
        "\n",
        "def applyKmersAndEncoding(seq):\n",
        "    k=3\n",
        "    tokens = [seq[i:i+k] for i in range(0, len(seq)-k+1)]\n",
        "    return tokens\n",
        "\n",
        "\n",
        "def encode_x_with_k_mer_one_hot_encoding(truncated_df):\n",
        "    truncated_df['Sequence'] = truncated_df.apply(lambda row: ''.join(map(str, row)), axis=1)\n",
        "    tokenized_sequences =  truncated_df['Sequence'].apply(applyKmersAndEncoding).tolist()\n",
        "    #print(tokenized_sequences)\n",
        "    # The result, tokenized_sequences, is a list of lists, where each inner list\n",
        "    #  contains the k-mers of the corresponding RNA sequence from the truncated_df list.\n",
        "\n",
        "\n",
        "    result = []\n",
        "    for seq in tokenized_sequences:\n",
        "        embedding = applyOneHotEncoding(seq)\n",
        "        result.append(embedding)\n",
        "    return np.array(result)\n",
        "\n",
        "# def generate_3mers(sequence):\n",
        "#     k = 3  # Length of k-mer\n",
        "#     three_mers = []\n",
        "#     for i in range(len(sequence) - k + 1):\n",
        "#         kmer = sequence[i:i+k]\n",
        "#         three_mers.append(''.join(kmer))\n",
        "#     return three_mers\n"
      ],
      "metadata": {
        "id": "vRGT6pWBX6cr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = x_train_raw.iloc[: , -1]\n",
        "x = x_train_raw.iloc[: , :-1]\n",
        "x_train_raw = None"
      ],
      "metadata": {
        "id": "5__BuaATbeom"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_3mers = encode_x_with_k_mer_one_hot_encoding(x)\n",
        "x_3mers\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M2LDW-xEX-dY",
        "outputId": "a3c10667-94ba-4d4c-c7c4-05fbcd693601"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 0, ..., 1, 0, 0],\n",
              "       [1, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 1, 0, ..., 1, 0, 0],\n",
              "       [0, 0, 1, ..., 0, 1, 0],\n",
              "       [0, 0, 1, ..., 0, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of Encoded Data : {x_3mers.shape} \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MNqSNt-HYCgi",
        "outputId": "31819e82-fd3d-434e-f356-e72910a8901d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Encoded Data : (309214, 1188) \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqkzl4y0axdg",
        "outputId": "78c85cc7-3dd3-4742-edb8-48ceeda3e25e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         hAm\n",
              "1         hAm\n",
              "2         hAm\n",
              "3         hAm\n",
              "4         hAm\n",
              "         ... \n",
              "309209    hAm\n",
              "309210    hAm\n",
              "309211    hAm\n",
              "309212    hAm\n",
              "309213    hAm\n",
              "Name: 101, Length: 309214, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# y_encoded_df = pd.get_dummies(y)\n",
        "# y_encoded_df\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "encoder = LabelEncoder()\n",
        "y_data = pd.Series(y.squeeze())\n",
        "y_encoded = encoder.fit_transform(y_data)\n",
        "\n",
        "unique, counts = np.unique(y_encoded, return_counts=True)\n",
        "value_counts = dict(zip(unique, counts))\n",
        "print(value_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pj4LVQ9yYFbA",
        "outputId": "b61b0ab0-5592-46d9-e8b8-f1c0ccbb0a01"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 154607, 1: 154607}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3J8LXsl_YHUc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First Convert it to Tensor then create Train/Test/Validation\n",
        "x_data = torch.tensor(x_3mers , dtype = torch.float32)\n",
        "y_data = torch.tensor(y_encoded , dtype = torch.float32)\n",
        "\n",
        "print(\"Generate Train and Split..\")\n",
        "# Train set\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(x_data, y_data, test_size=0.3, random_state=42)\n",
        "\n",
        "# Test and Validation set\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSfRHHUaYJyu",
        "outputId": "519ea848-fc51-4bbd-8a7e-6c7a9681eaa2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generate Train and Split..\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data = None\n",
        "y_data = None\n",
        "y_encoded_df = None\n",
        "x_3mers = None\n",
        "x  = None\n",
        "y = None\n",
        "X_temp = None\n",
        "y_temp = None"
      ],
      "metadata": {
        "id": "IZmtN6l9a5qM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "emSmUkV1cY6K",
        "outputId": "3e51c9eb-ac79-44fc-da96-191d14476bbe"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216449, 1188])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define a class to build trainloader\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = features\n",
        "        self.targets = targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.targets[idx]"
      ],
      "metadata": {
        "id": "L6WaHOgba-Ps"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 32\n",
        "\n",
        "train_dataset = MyDataset(X_train, y_train)\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True,  batch_size=batch_size)\n",
        "\n",
        "# get testloader\n",
        "test_dataset = MyDataset(X_test, y_test)\n",
        "test_dataloader = DataLoader(test_dataset, shuffle=False,  batch_size=batch_size)\n",
        "\n",
        "valid_dataset = MyDataset(X_valid, y_valid)\n",
        "valid_dataloader = DataLoader(valid_dataset, shuffle=False, batch_size=batch_size)\n"
      ],
      "metadata": {
        "id": "VUv2o9eZa_CL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of X train : \" , len(X_train[0]))\n",
        "for inputs, labels in test_dataloader:\n",
        "    print(inputs.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unF3EMnEdjkc",
        "outputId": "bd008df4-677d-41e7-e977-926241059875"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X train :  1188\n",
            "torch.Size([32, 1188])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GRUModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, dropout_prob , embedding_dim):\n",
        "        super(GRUModel, self).__init__()\n",
        "\n",
        "        # Defining the number of layers and the nodes in each layer\n",
        "        self.layer_dim = layer_dim #layer of GRU\n",
        "        self.hidden_dim = hidden_dim #32,64...\n",
        "        # input_dim is the number of feature dimension (X)\n",
        "\n",
        "        self.embedding = nn.Embedding(input_dim, embedding_dim)\n",
        "\n",
        "        # GRU layers\n",
        "        self.gru = nn.GRU(\n",
        "            embedding_dim, hidden_dim, layer_dim, batch_first=True, dropout=dropout_prob\n",
        "        )\n",
        "\n",
        "        # Fully connected layer\n",
        "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout_prob)\n",
        "\n",
        "\n",
        "    def forward(self, x): #what to do when 1 epoch layer is done\n",
        "        # Initializing hidden state for first input with zeros\n",
        "        #h0 = torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).requires_grad_()\n",
        "\n",
        "        x  = x.long()\n",
        "        #print(f\"Shape of X  : {x.shape}\")\n",
        "\n",
        "        x_embedded =  self.embedding(x)\n",
        "\n",
        "        #print(f\"Shape of X  : {x_embedded.shape}\")\n",
        "        # Forward propagation by passing in the input and hidden state into the model\n",
        "        gru_out , h = self.gru(x_embedded)\n",
        "\n",
        "        #print(f\"Shape of gru_out  : {gru_out.shape}\")\n",
        "\n",
        "        # Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\n",
        "        # so that it can fit into the fully connected layer\n",
        "\n",
        "        #print(f\"Shape of Ouput Layer : {h.shape}\")\n",
        "        out = gru_out[:,-1,:] # pick up last hidden state\n",
        "\n",
        "        # Convert the final state to our desired output shape (batch_size, output_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        # Adding drop layer to avoid over fitting\n",
        "        out = self.dropout(out)\n",
        "\n",
        "        return out.squeeze() # Squeeze to remove extra dimension"
      ],
      "metadata": {
        "id": "XfgYA4f2bAhR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(model, model_params):\n",
        "    models = {\n",
        "        \"gru\": GRUModel,\n",
        "    }\n",
        "    return models.get(\"gru\")(**model_params)"
      ],
      "metadata": {
        "id": "OaDWSD85bDY5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def validate_model(model, test_dataloader , device ,loss_function):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_dataloader:\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.float().to(device)\n",
        "            outputs = model(inputs)\n",
        "            if outputs.size() != labels.size(): # skip if batch size mismatch\n",
        "              print(f\"Test Mismatch Found {outputs.size()} , and {labels.size()}\")\n",
        "              #break\n",
        "              continue\n",
        "            #print(f\"Shape of Label : {labels.shape} and output shape : {outputs.shape} \")\n",
        "            loss = loss_function(outputs, labels)\n",
        "            running_loss += loss.item()\n",
        "\n",
        "            predicted = (torch.sigmoid(outputs) > 0.5).float() # Set threshold at 0.5\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            true_labels.extend(labels.cpu().numpy())  # Capture True Labels for Summary Report\n",
        "            predicted_labels.extend(predicted.cpu().numpy()) # Capture Predicted Labels Lables for Summary Report\n",
        "\n",
        "    validation_loss = running_loss / len(test_dataloader)\n",
        "    validation_accuracy = correct / total\n",
        "\n",
        "    return validation_loss , validation_accuracy , true_labels , predicted_labels\n",
        "\n",
        "\n",
        "\n",
        "def train_model(model, train_dataloader, test_dataloader, device, epochs, optimizer, loss_function):\n",
        "    best_val_loss = float('inf')\n",
        "    no_improvement_count = 0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        start_time = time.time()\n",
        "        #progress_bar = tqdm(train_dataloader, desc='Epoch {:03d}'.format(epoch + 1), leave=False, disable=False)\n",
        "        for i, (inputs, labels) in enumerate(train_dataloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.float().to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            if outputs.size() != labels.size(): # skip if batch size mismatch\n",
        "              print(f\"Train Mismatch Found {outputs.size()} , and {labels.size()}\")\n",
        "              #break\n",
        "              continue\n",
        "            #print(f\"Shape of Label : {labels.shape} and output shape : {outputs.shape} \")\n",
        "            loss = loss_function(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            #progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(inputs))})\n",
        "\n",
        "        epoch_loss = running_loss / len(train_dataloader)\n",
        "        val_loss,  validation_accuracy , true_labels , predicted_labels = validate_model(model, test_dataloader, device, loss_function)\n",
        "        end_time = time.time()\n",
        "        elapsed_time = end_time - start_time\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_loss:.4f}, Test Accuracy: {validation_accuracy:.4f} , Time Taken : {elapsed_time}\")\n",
        "\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            no_improvement_count = 0\n",
        "        else:\n",
        "            no_improvement_count += 1\n",
        "            if no_improvement_count == 10:\n",
        "                print(\"No improvement in validation loss for 5 epochs. Training stopped.\")\n",
        "                break\n",
        "\n"
      ],
      "metadata": {
        "id": "ZYr5p2pEbF8I"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "input_dim = len(X_train[0])\n",
        "output_dim = 1\n",
        "embedding_dim = 32\n",
        "hidden_dim = 7\n",
        "layer_dim = 3\n",
        "batch_size = 32\n",
        "# batch size dhould be 32,64,128 ..\n",
        "dropout = 0.2\n",
        "n_epochs = 10\n",
        "learning_rate = 1e-3\n",
        "weight_decay = 1e-6\n",
        "device = torch.device(\"cpu\")\n",
        "\n",
        "model_params = {'input_dim': input_dim,\n",
        "                'embedding_dim' : embedding_dim,\n",
        "                'hidden_dim' : hidden_dim,\n",
        "                'layer_dim' : layer_dim,\n",
        "                'output_dim' : output_dim,\n",
        "                'dropout_prob' : dropout}\n",
        "\n",
        "model = get_model('gru', model_params)\n",
        "\n",
        "loss_fn = nn.BCEWithLogitsLoss()  ## MSELoss of Regression problem  # BCELoss for binary classification\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)\n",
        "\n",
        "\n",
        "# Number of Parameters for Model\n",
        "total_parameters = []\n",
        "for p in model.parameters():\n",
        "    total_parameters.append(p.numel())\n",
        "\n",
        "print(f\"Total Number of Parameters for Model Training : { sum(total_parameters)} \" )\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "print(\"Model Parameters  : \" , model_params)\n",
        "\n",
        "# Train Model with configured Parameter\n",
        "train_model(model, train_dataloader ,test_dataloader, device ,n_epochs,optimizer,loss_fn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYVzuP-QbFvX",
        "outputId": "953b67d4-5460-4d81-a2f5-0ea55c96f219"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Number of Parameters for Model Training : 39557 \n",
            "Model Parameters  :  {'input_dim': 1188, 'embedding_dim': 32, 'hidden_dim': 7, 'layer_dim': 3, 'output_dim': 1, 'dropout_prob': 0.2}\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 1, Train Loss: 0.6908, Val Loss: 0.6857, Test Accuracy: 0.5497 , Time Taken : 62.693838119506836\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 2, Train Loss: 0.6885, Val Loss: 0.6952, Test Accuracy: 0.4925 , Time Taken : 63.1167151927948\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 3, Train Loss: 0.6922, Val Loss: 0.6906, Test Accuracy: 0.5401 , Time Taken : 62.62605285644531\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 4, Train Loss: 0.6871, Val Loss: 0.6819, Test Accuracy: 0.5731 , Time Taken : 62.77819013595581\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 5, Train Loss: 0.6590, Val Loss: 0.6448, Test Accuracy: 0.6314 , Time Taken : 62.667418241500854\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 6, Train Loss: 0.6562, Val Loss: 0.6456, Test Accuracy: 0.6283 , Time Taken : 63.47010827064514\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 7, Train Loss: 0.6533, Val Loss: 0.6409, Test Accuracy: 0.6341 , Time Taken : 63.57279300689697\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 8, Train Loss: 0.6623, Val Loss: 0.6384, Test Accuracy: 0.6445 , Time Taken : 63.50500130653381\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 9, Train Loss: 0.6490, Val Loss: 0.6360, Test Accuracy: 0.6457 , Time Taken : 62.909485816955566\n",
            "Train Mismatch Found torch.Size([]) , and torch.Size([1])\n",
            "torch.Size([32, 1188])\n",
            "Epoch 10, Train Loss: 0.6445, Val Loss: 0.6320, Test Accuracy: 0.6446 , Time Taken : 63.35175919532776\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test dataset\n",
        "_, final_accuracy, true_labels, predicted_labels = validate_model(model, valid_dataloader,device,loss_fn)\n",
        "\n",
        "# Print the final accuracy\n",
        "print(f\"Final Accuracy: {final_accuracy:.4f}\")\n",
        "\n",
        "# Print the classification summary\n",
        "print(\"\\n Classification Summary:\")\n",
        "print(classification_report(true_labels, predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I-UQYS9cbLC3",
        "outputId": "fa0a1488-0975-45b8-a9dc-e0ea79226c8d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([32, 1188])\n",
            "Final Accuracy: 0.6406\n",
            "\n",
            " Classification Summary:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.65      0.60      0.63     23309\n",
            "         1.0       0.63      0.68      0.65     23073\n",
            "\n",
            "    accuracy                           0.64     46382\n",
            "   macro avg       0.64      0.64      0.64     46382\n",
            "weighted avg       0.64      0.64      0.64     46382\n",
            "\n"
          ]
        }
      ]
    }
  ]
}